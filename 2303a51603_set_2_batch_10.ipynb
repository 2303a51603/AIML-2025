{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDSJwUOePtgOhkZn/KoG93",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a51603/AIML-2025/blob/main/2303a51603_set_2_batch_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction of News Popularity in Social Media Platforms\n",
        "\n",
        "Q1.Identify the max and min popularities of news among the social platforms?\n",
        "\n",
        "Q2. Identify the date and time when news popularity was the most?\n",
        "\n",
        "Q3. Predict the social media platform with most popularity?\n",
        "\n",
        "Q4. What types of news items is suitable and not suitable for social media?\n",
        "\n",
        "Q5. Does news contribute to increase or decrease of social media popularity"
      ],
      "metadata": {
        "id": "BcYSZgtw7_7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1"
      ],
      "metadata": {
        "id": "0YbgpdfBAn-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m-KMvCFU8Eti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def handle_query(query):\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv('file.csv')  # Replace with your dataset path\n",
        "\n",
        "    if query == \"MAX_POPULARITY\":\n",
        "        return data['popularity'].max()\n",
        "    elif query == \"MIN_POPULARITY\":\n",
        "        return data['popularity'].min()\n",
        "    else:\n",
        "        return \"Invalid query\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example input from AIML\n",
        "    user_query = input(\"Enter Query (MAX_POPULARITY/MIN_POPULARITY): \").strip()\n",
        "    result = handle_query(user_query)\n",
        "    print(f\"RESULT {result}\")\n"
      ],
      "metadata": {
        "id": "Pjg6DgL5BhUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2"
      ],
      "metadata": {
        "id": "aMyJogq-BktX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_max_date_time():\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv('file.csv')  # Replace with your dataset path\n",
        "\n",
        "    # Find the row with maximum popularity\n",
        "    max_popularity_row = data.loc[data['popularity'].idxmax()]\n",
        "\n",
        "    # Extract date and time\n",
        "    max_date = max_popularity_row['date']\n",
        "    max_time = max_popularity_row['time']\n",
        "\n",
        "    return f\"{max_date} {max_time}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Simulate input from AIML\n",
        "    query = input(\"Enter Query (MAX_DATE_TIME): \").strip()\n",
        "\n",
        "    if query == \"MAX_DATE_TIME\":\n",
        "        result = get_max_date_time()\n",
        "        print(f\"RESULT {result}\")\n",
        "    else:\n",
        "        print(\"Invalid query\")\n"
      ],
      "metadata": {
        "id": "2cohN1MnBnlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3"
      ],
      "metadata": {
        "id": "icrp2vM2CPDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def predict_most_popular_platform():\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv('file.csv')  # Replace with your dataset path\n",
        "\n",
        "    # Assume platform popularity columns\n",
        "    platforms = ['popularity_facebook', 'popularity_twitter', 'popularity_instagram']\n",
        "\n",
        "    # Calculate total popularity for each platform\n",
        "    total_popularity = {platform: data[platform].sum() for platform in platforms}\n",
        "\n",
        "    # Find the platform with the highest total popularity\n",
        "    most_popular_platform = max(total_popularity, key=total_popularity.get)\n",
        "\n",
        "    return most_popular_platform\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Simulate input from AIML\n",
        "    query = input(\"Enter Query (MOST_POPULAR_PLATFORM): \").strip()\n",
        "\n",
        "    if query == \"MOST_POPULAR_PLATFORM\":\n",
        "        result = predict_most_popular_platform()\n",
        "        print(f\"RESULT {result}\")\n",
        "    else:\n",
        "        print(\"Invalid query\")\n"
      ],
      "metadata": {
        "id": "VuB-AI3xCRch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4"
      ],
      "metadata": {
        "id": "aGBui8dsCkL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def analyze_news_suitability(query):\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv('file.csv')  # Replace with your dataset path\n",
        "\n",
        "    # Group data by news type and calculate average popularity\n",
        "    news_popularity = data.groupby('news_type')['popularity'].mean().sort_values(ascending=False)\n",
        "\n",
        "    if query == \"SUITABLE_NEWS\":\n",
        "        # Find the top 3 most popular news types\n",
        "        suitable_news = news_popularity.head(3).index.tolist()\n",
        "        return f\"Suitable news types are: {', '.join(suitable_news)}\"\n",
        "    elif query == \"UNSUITABLE_NEWS\":\n",
        "        # Find the 3 least popular news types\n",
        "        unsuitable_news = news_popularity.tail(3).index.tolist()\n",
        "        return f\"Unsuitable news types are: {', '.join(unsuitable_news)}\"\n",
        "    else:\n",
        "        return \"Invalid query\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Simulate input from AIML\n",
        "    query = input(\"Enter Query (SUITABLE_NEWS/UNSUITABLE_NEWS): \").strip()\n",
        "\n",
        "    result = analyze_news_suitability(query)\n",
        "    print(f\"RESULT {result}\")\n"
      ],
      "metadata": {
        "id": "GzFGuoaSClZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5"
      ],
      "metadata": {
        "id": "5A125HUSC9-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def analyze_news_contribution():\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv('file.csv')  # Replace with your dataset path\n",
        "\n",
        "    # Assuming columns 'news_popularity' and 'social_media_popularity' exist\n",
        "    if 'news_popularity' in data.columns and 'social_media_popularity' in data.columns:\n",
        "        # Calculate correlation between news popularity and social media popularity\n",
        "        correlation, _ = pearsonr(data['news_popularity'], data['social_media_popularity'])\n",
        "\n",
        "        if correlation > 0.5:\n",
        "            return \"News significantly increases social media popularity.\"\n",
        "        elif correlation > 0:\n",
        "            return \"News slightly increases social media popularity.\"\n",
        "        elif correlation < -0.5:\n",
        "            return \"News significantly decreases social media popularity.\"\n",
        "        else:\n",
        "            return \"News slightly decreases social media popularity.\"\n",
        "    else:\n",
        "        return \"Required data columns are missing in the dataset.\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Simulate input from AIML\n",
        "    query = input(\"Enter Query (NEWS_CONTRIBUTION): \").strip()\n",
        "\n",
        "    if query == \"NEWS_CONTRIBUTION\":\n",
        "        result = analyze_news_contribution()\n",
        "        print(f\"RESULT {result}\")\n",
        "    else:\n",
        "        print(\"Invalid query\")\n"
      ],
      "metadata": {
        "id": "LFHNubN8C-sI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}